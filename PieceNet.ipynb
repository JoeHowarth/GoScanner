{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import keras\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import h5py\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image as Pim\n",
    "\n",
    "from input_utils import showImg, get_images, crop, expand_rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "img = load_img('./data/train/white/1-(3.4).png')  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "print(x.shape)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='data/preview', save_prefix='cat', save_format='jpeg'):\n",
    "    print(batch.shape)\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "h5py.run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=5,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=(151, 151),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/test',\n",
    "        target_size=(151, 151),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(151, 151, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3 , activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch= 350 // batch_size,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=150 // batch_size)\n",
    "model.save_weights('models/first_try.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## \n",
    "# model architecture\n",
    "\n",
    "#model = Sequential()\n",
    "#\n",
    "#model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(151,151,3)))\n",
    "#model.add(Conv2D(32, (5, 5), activation='relu'))\n",
    "#\n",
    "#model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.25))\n",
    "#\n",
    "#model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "#model.add(Conv2D(10, (3, 3), activation='relu'))\n",
    "#\n",
    "#model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "##model.add(Dropout(0.25))\n",
    "#\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(3, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss = 'categorical_crossentropy', \n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, batch_size=32, validation_split=.1, \n",
    "          epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "scores.append(score)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#datagen = ImageDataGenerator(\n",
    "            rotation_range=40,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Train on 47500 samples, validate on 2500 samples\n",
    "Epoch 1/10\n",
    "47500/47500 [==============================] - 17s - loss: 1.8500 - acc: 0.2935 - val_loss: 1.5302 - val_acc: 0.4248\n",
    "Epoch 2/10\n",
    "47500/47500 [==============================] - 16s - loss: 1.4836 - acc: 0.4611 - val_loss: 1.2951 - val_acc: 0.5436\n",
    "Epoch 3/10\n",
    "47500/47500 [==============================] - 16s - loss: 1.3042 - acc: 0.5345 - val_loss: 1.1538 - val_acc: 0.5804\n",
    "Epoch 4/10\n",
    "47500/47500 [==============================] - 16s - loss: 1.1980 - acc: 0.5754 - val_loss: 1.0844 - val_acc: 0.6224\n",
    "Epoch 5/10\n",
    "47500/47500 [==============================] - 16s - loss: 1.1024 - acc: 0.6129 - val_loss: 0.9991 - val_acc: 0.6492\n",
    "Epoch 6/10\n",
    "47500/47500 [==============================] - 16s - loss: 1.0362 - acc: 0.6367 - val_loss: 1.0078 - val_acc: 0.6436\n",
    "Epoch 7/10\n",
    "47500/47500 [==============================] - 16s - loss: 0.9887 - acc: 0.6578 - val_loss: 0.9196 - val_acc: 0.6700\n",
    "Epoch 8/10\n",
    "47500/47500 [==============================] - 16s - loss: 0.9528 - acc: 0.6706 - val_loss: 0.8934 - val_acc: 0.6868\n",
    "Epoch 9/10\n",
    "47500/47500 [==============================] - 16s - loss: 0.9223 - acc: 0.6807 - val_loss: 0.8991 - val_acc: 0.6920\n",
    "Epoch 10/10\n",
    "47500/47500 [==============================] - 16s - loss: 0.8877 - acc: 0.6911 - val_loss: 0.8717 - val_acc: 0.6900"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
